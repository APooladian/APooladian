### About me

I'm at PhD student at the Center for Data Science at New York University, where my advisor is Professor Jonathan Niles-Weed. Before joining the CDS, I completed both my Bachelor's and Master's degrees in (applied) mathematics at McGill University, the latter under the supervision of Tim Hoheisel and Adam Oberman.

#### Research interests
High-dimensional statistics (e.g. computational and statistical optimal transport), optimization theory (stochastic, convex, and non-smooth), and problems in deep learning (e.g. normalizing flows)

### Current code in this repo
In this repo, there is code available for a few papers/pre-prints that I've worked on during my MSc. Most noteably:
- the repo for the  "LogBarrier" adversarial attack (published at ICCV 2019), 
- the extension to non-smooth dissimilarity metrics (e.g. &#8467;<sub>1</sub>, &#8467;<sub>2</sub>, &#8467;<sub>0</sub>, &#8467;<sub>&infin;</sub>, and Total Variation), called "ProxLogBarrier" (published at AISTATS 2020), 
- a small repo for using the Ordered-Weighted L1 norm as an attack dissimilarity metric via the ProxLogBarrier framework
- the repo for "FarkasLayers" (pre-print), which uses basic notions of the well-known Farkas lemma to explain how batch normalization works
- a small repo for understanding batch-wise projections under the total variation seminorm

### Code to come (hopefully)
- Code for "Normalizing flows using Entropy-Kantorovich potentials" (accepted to INNF+ workshop, with contributing talk)
- Code for my MSc thesis on the Fermat-Weber problem in polyhedral norms

#### Contact
Either aram-alexandre[dot]pooladian[at]mail[dot]mcgill[dot]ca or aram-alexandre[dot]pooladian[at]nyu[dot]edu
